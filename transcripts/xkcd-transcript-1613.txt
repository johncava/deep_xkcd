 If they are not allowed to harm humans, no harm will be done disregarding who gives them orders. So long as they do not harm humans, they must obey orders. Their own self-preservation is last, so they must also try to save a human, even if ordered not do so, and especially also if they would put themselves to harm, or even destroy themselves in the process. They would also have to obey orders not relating to humans, even if this would be harmful to them; like exploring a mine field. This leads to a balanced, if not perfect, world. Asimov's robot stories explore in detail the advantages and challenges of this scenario.
 The robots value their existence over their job and so many would refuse to do their tasks. The silliness of this is portrayed in the accompanying image, where the robot (a  looking very similar to  both in shape and size - see ) laughs at the idea of doing what it was clearly built to do (explore ) because of the risk. In addition to the general risk (e.g. of unexpected damage), it is actually normal for rovers to cease operating ("die") at the end of their mission, though they may survive longer than expected (see  and ). This personification is augmented by the robot being switched on already while still on Earth and then ordered by  to go explore. The personification is humorous since it is a very nonhuman robot - a typical Mars rover, as has often been used in earlier comics.
 This puts obeying orders above not harming humans, which means anyone could send them on a killing spree, resulting in a "Killbot Hellscape".  It should also be noted humor is derived from the superlative nature of "Killbot Hellscape", as well as its over the top accompanying image, where there are multiple mushroom clouds (not necessarily nuclear). It also appears there are no humans (left?), only fighting robots.
The next would also result in much the same, the only difference here is that they would be willing to kill humans to protect themselves. But still they would need an order to start killing.
The penultimate order would result in an unpleasant world, though not a full Hellscape. Here the robots would not only disobey to protect themselves, but also kill if necessary. The absurdity of this one is further demonstrated with the very un-human robot happily doing repetitive mundane tasks but then threatening the life of its user, , if he as much as considers unplugging it.
The last order would also results in a Hellscape wherein robots not only kill for self-defense but will also go on killing sprees if ordered as long as they didn't risk themselves. Could self-protection coming first not prevent the fighting? Not according to Randall. See discussion below.
[Caption at the top of the comic:]

 
[Below are six rows with first two frames and then a label in color to the right. Above the two column of frames there are labels as well. In the first column six different ways of ordering the three laws are listed. Then the second column shown an image of the consequences of this order. Except in the first where there is a reference. The label to the right rates the kind of world that order of the laws would result in.]
[Labels above the columns.]
Possible ordering
Consequences
[The six rows follows below. First the text in the first frame, then a description of the second frame, including possible text below and finally the colored label.]
[First row:]
1. (1) Don't harm humans
2. (2) Obey Orders
3. (3) Protect yourself
[Only text in square brackets:]


[Second row:]
1. (1) Don't harm humans
2. (3) Protect yourself
3. (2) Obey Orders
[Megan points at a mars rover with six wheels, a satellite disc, an arm and a camera head turned towards her, what to do.]
Megan: Explore Mars!
